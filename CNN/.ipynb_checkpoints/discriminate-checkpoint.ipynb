{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discriminate task and Attention map view\n",
    "### 疾患部位診断"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'attrdict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mseaborn\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39msns\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mcopy\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mattrdict\u001b[39;00m \u001b[39mimport\u001b[39;00m AttrDict\n\u001b[1;32m     10\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39myaml\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'attrdict'"
     ]
    }
   ],
   "source": [
    "from PIL import Image,ImageDraw\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import japanize_matplotlib # seaborn日本語表記用\n",
    "import seaborn as sns\n",
    "\n",
    "import copy\n",
    "from attrdict import AttrDict\n",
    "\n",
    "import os\n",
    "import yaml\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from sklearn.metrics import confusion_matrix,f1_score,classification_report, accuracy_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix \n",
    "\n",
    "from models import resnet_base_network_all, resnet_base_network_each\n",
    "from data.create_dataset import create_dataloader, create_dataloader_18,create_dataloader_only12\n",
    "\n",
    "from models import resnet_base_network_all, resnet_base_network_each, MHBN, GVCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configとモデルパラメータの参照先の取得\n",
    "da = True \n",
    "num_lead = 12\n",
    "task=5\n",
    "io = 0\n",
    "\n",
    "input_order = ['in_asc','in_rand']\n",
    "\n",
    "model_name = 'MVCNN'\n",
    "layer = 'CNN4'\n",
    "cls_ = 'MLP'\n",
    "\n",
    "exppath = './runs/view{}_{}_{}/'.format(num_lead,task,input_order[io]) \n",
    "\n",
    "model_path = os.path.join(exppath, '{}_{}'.format(model_name,layer), 'each', cls_)\n",
    "config = yaml.load(open(os.path.join(model_path,\"config.yaml\"), \"r\"), Loader=yaml.FullLoader) # load config\n",
    "\n",
    "type_ = config.type\n",
    "batch_size = config.model_conf.batch_size\n",
    "input_size = config.model_conf.input_size\n",
    "\n",
    "# 辞書変数をオブジェクト変数に\n",
    "config = AttrDict(config)\n",
    "\n",
    "batch_size=16\n",
    "if num_lead == 12:\n",
    "    if task == 2:\n",
    "        data_dir = './dataset/ECG100_224_2class/'\n",
    "        train_dataloader, test_dataloader, label_name, train_len, test_len = create_dataloader_only12(data_dir, batch_size,input_size,seed,io,da)\n",
    "        print('Data Augumentation : ', da)\n",
    "\n",
    "    elif task == 4:\n",
    "        data_dir = './dataset/ECG100_224_ACS/'\n",
    "        train_dataloader, test_dataloader, label_name, train_len, test_len = create_dataloader_only12(data_dir, batch_size,input_size,seed,io,da)\n",
    "        print('Data Augumentation : ', da)\n",
    "\n",
    "    elif task == 5:\n",
    "        data_dir = './dataset/ECG100_224/'\n",
    "        train_dataloader, test_dataloader, label_name, train_len, test_len = create_dataloader_only12(data_dir, batch_size,input_size,seed,io,da)\n",
    "        print('Data Augumentation : ', da)\n",
    "                \n",
    "elif num_lead == 18:\n",
    "    if task == 2:\n",
    "        data_dir = './dataset/ECG100_224_2class/'\n",
    "        train_dataloader, test_dataloader, label_name, train_len, test_len = create_dataloader_18(data_dir, batch_size,input_size,seed,io,da)\n",
    "        print('Data Augumentation : ', da)\n",
    "            \n",
    "    elif task == 4:\n",
    "        data_dir = './dataset/ECG100_224_ACS/'\n",
    "        train_dataloader, test_dataloader, label_name, train_len, test_len = create_dataloader_18(data_dir, batch_size,input_size,seed,io,da)\n",
    "\n",
    "    elif task == 5:\n",
    "        data_dir = './dataset/ECG100_224/'\n",
    "        train_dataloader, test_dataloader, label_name, train_len, test_len = create_dataloader_18(data_dir, batch_size,input_size,seed,io,da)\n",
    "        print('Data Augumentation : ', da)\n",
    "    \n",
    "elif num_lead == 19:\n",
    "    if task == 2:\n",
    "        data_dir = './dataset/ECG100_224_2class/'\n",
    "        train_dataloader, test_dataloader, label_name, train_len, test_len = create_dataloader(data_dir, batch_size,input_size,seed,io,da)\n",
    "        print('Data Augumentation : ', da)\n",
    "\n",
    "    elif task == 4:\n",
    "        data_dir = './dataset/ECG100_224_ACS/'\n",
    "        train_dataloader, test_dataloader, label_name, train_len, test_len = create_dataloader(data_dir, batch_size,input_size,seed,io,da)\n",
    "        print('Data Augumentation : ', da)\n",
    "            \n",
    "    elif task == 5:\n",
    "        data_dir = './dataset/ECG100_224/'\n",
    "        train_dataloader, test_dataloader, label_name, train_len, test_len = create_dataloader(data_dir, batch_size,input_size,seed,io,da)\n",
    "        print('Data Augumentation : ', da)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "print(f\"Training with: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9fbad985084092e4930b8351703378d22dcca7c1d3a7c77933cc15af6668fbee"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
